# Evaluating and Circumventing Safety Measures in Large Language Models through Adversarial LoRA Fine-Tuning

This repository contains the code and resources for the final project in the EL-GY-9163: Machine Learning for Cyber-security class. The project evaluates the vulnerability of large language models (LLMs) to adversarial fine-tuning using Low-Rank Adaptation (LoRA), focusing on the robustness of safety measures in LLMs against subversive manipulations.
